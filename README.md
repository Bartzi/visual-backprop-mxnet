# Implementation of Visual Backprop for MXNet

This repo contains an implementation of [VisualBackProp](https://arxiv.org/abs/1611.05418) for [MXNet](http://mxnet.io/).

# Requirements

0. Make sure to use **Python 3**
1. Install MXNet as shown [here](http://mxnet.io/get_started/install.html).
2. Install further requirements by issuing `pip install -r requirements.txt`

# Usage

The file `vis_backprop_test.py` contains a sample that trains MNIST and performs VisualBackprop on every forward pass.
Adding VisualBackProp to your own code ist quite easy. You have to perform the following steps:

1. adapt your `symbol` definition, by adding a call to `insights.build_visual_backprop_symbol` after the activation of the convolutional layer you want to visualize.
2. keep the returned visualization `symbol` for the visualization pass.
3. create an instance of the `VisualBackpropPlotter` class, providing an ip and port for the visualization endpoint.
4. get one sample image where you want to visualize the convolution.
5. add a new `batch_end_callback` to your model, by calling the method `get_callback` of the created `VisualBackpropPlotter` object.
6. start the `show_progress.py` tool, that you can find in the `utils` directory, by issuing the following command: `python show_progress.py`. (This tool is the visualization endpoint)
7. Sit back and enjoy!

# How does it work?

`insights.build_visual_backprop_symbol` adds a new subgraph to the computational graph that performs the necessary operations for VisualBackProp (see the paper for more details).
During a forward pass MXNet calls the callback implemented in `VisualBackpropPlotter`. This callback copies the current params and performs a forward pass with the given input data.
After this forward pass, the output generated by the VisualBackProp branch is extracted and converted into an image. Together with the original image, this image is send to the visualization endpoint.

# License

This code is licensed under the GPLv3 license.
